## Course Questions - Lecture 4 
* What is deadlocking?
Deadlocking is a situation that occurs when two or more processes or threads are blocked and unable to proceed because they are waiting for a resource that is held by one of the other processes. Deadlocking can occur when there is a circular dependency between the processes, where each process is waiting for a resource that is held by another process, which is waiting for a resource held by another process, and so on. 
* Who was Dijkstra? 
Edsger W. Dijkstra was a Dutch computer scientist and mathematician who made significant contributions to the field of computer science. He is best known for his work on algorithms and programming languages, and is considered one of the pioneers of the field of computer science.
He is particularly known for his work on the shortest path algorithm, which is used to find the shortest path between two points in a graph, and his contributions to the design of the programming language ALGOL.
* What are the 4 deadlock conditions?
Mutual exclusion:  “Only one process at a time can use the resource.”
Hold and wait: “When a process is waiting for an other process to release a resource.”
No preemption: “A resource can only be relased voluntarily by the proces itself and cannot be taken by another proces.”
Circular wait: “A set of processes waiting for each other to form a chain structure. P1 is waiting for P2 to finish while P2 is waiting for P3, ... Pn is waiting for P1.”
* What is the difference between deadlock avoidance & deadlock prevention?
avoidance: “Deadlock avoidance involves taking steps to avoid getting into a situation where two or more processes or threads are blocked and unable to proceed because they are waiting for a resource that is held by one of the other blocked processes. This can be achieved through the use of protocols or rules that dictate how processes or threads request resources, so that they do not request resources in a way that could lead to a deadlock.”
prevention: “Deadlock prevention involves designing the system in such a way that it is impossible for a deadlock to occur. This can be achieved through the use of resource ordering, where resources are always requested in a fixed order, or through the use of a resource allocation algorithm that ensures that processes or threads only request resources that they can safely obtain without causing a deadlock.”
* What are safe sequences and why are they interesting?
A safe sequence is a sequence of resource allocation and release actions that, if followed, would not result in deadlock. Safe sequences are of interest because they provide a way to prevent or avoid deadlocks by ensuring that resources are always requested and released in a way that avoids the possibility of deadlock.
* What is the concept of virtual memory?
Virtual memory is a feature of an operating system (OS) that enables a computer to be able to compensate for shortages of physical memory by temporarily transferring pages of data from random access memory (RAM) to disk storage. This enables the computer to be able to run larger programs and perform tasks that would not be possible with the limited physical memory available.
* What is the difference between the difference layer caches (1,2,3)?
Level 1 (L1) cache is the fastest and smallest type of cache memory. It is located on the same chip as the processor and is used to store data and instructions that the processor is most likely to access next. L1 cache is typically very small, on the order of a few kilobytes, and is accessed in a few clock cycles.
Level 2 (L2) cache is slower and larger than L1 cache. It is also located on the processor chip, but is separate from the L1 cache. L2 cache is used to store data and instructions that the processor is likely to access, but not as frequently as those stored in L1 cache. L2 cache is typically larger than L1 cache, on the order of a few megabytes, and is accessed in a few tens of clock cycles.
Level 3 (L3) cache is even larger and slower than L2 cache. It is not located on the processor chip, but is instead located on a separate chip or in main memory. L3 cache is used to store data and instructions that the processor is not likely to access frequently, but that are still needed for the current task. L3 cache is typically much larger than L1 and L2 cache, on the order of a few hundred megabytes or more, and is accessed in a few hundred clock cycles or more.
* What is the difference between an executable and a process?
An executable is a file that contains a program that can be run on a computer. It is typically stored on disk storage and can be launched by a user or by another program. An executable file typically has a file extension that indicates its format, such as .exe for a Windows executable or .app for a macOS application.
A process is an instance of a program that is being executed by the operating system (OS). When an executable is launched, the OS creates a new process to run the program. A process has its own memory space, which is used to store the program's code and data, as well as its own execution state, which includes information about the program's current location and other runtime details.
* What is "swapping"?
Memory swapping is a technique used by operating systems to free up physical memory (RAM) when the system is running low on available memory. When the system runs out of physical memory, it can use a portion of the hard drive (known as virtual memory) to store data that is not being used immediately. This allows the system to continue running and avoid crashing due to a lack of available memory.
When the system needs to access data that is stored in virtual memory, it must first swap the data back into physical memory before it can be used. This process, known as "swapping," involves transferring the data from the hard drive to RAM, which can be a slower process than accessing data that is already in RAM.
* What is partitioning, paging, segmentation in the context of memory layout strategy's. Are they consecutive memory allocation or non-consecutive?
Partitioning, paging, and segmentation are methods for dividing a computer's physical memory into sections that can be assigned to different programs or processes.
Partitioning is a method of dividing a computer's physical memory into sections, or partitions, that can be assigned to different programs or processes. Each partition is a contiguous block of memory that is assigned to a specific program or process. Partitioning is a form of consecutive memory allocation, meaning that the memory blocks are assigned to programs or processes in a sequential manner, with no gaps or empty spaces between them.
Paging is a method of dividing a computer's physical memory into fixed-size blocks called pages, which can be assigned to programs or processes as needed. When a program or process needs to access a particular block of memory, the operating system retrieves the appropriate page from main memory and stores it in a special high-speed memory buffer called a cache. Paging is a form of non-consecutive memory allocation, as the pages are not necessarily stored in contiguous blocks of memory.
Segmentation is a method of dividing a computer's physical memory into variable-size blocks called segments, which can be assigned to programs or processes as needed. Each segment is a block of memory that is assigned to a specific program or process and is used to store a specific type of data or code. Segmentation is also a form of non-consecutive memory allocation, as the segments are not necessarily stored in contiguous blocks of memory.
* What is trashing?
Trashing is a phenomenon that occurs when a computer's central processing unit (CPU) is unable to keep up with the demands of the programs and processes that are running on it. When this happens, the CPU spends most of its time swapping data in and out of main memory, rather than executing instructions.
* What is the difference between a page and a frame?
In the context of computer memory, a page refers to a fixed-size block of memory that is used for virtual memory management. When a computer's main memory (also known as RAM) is full, the operating system can move some of the data to a special area on the hard drive called a swap file or paging file. This allows the computer to continue running smoothly even when its RAM is full.
A frame, on the other hand, refers to a contiguous block of memory that is allocated to a specific process or application. The operating system keeps track of which frames are allocated to which processes, and can move data between frames and the swap file as needed to manage the overall use of memory.
* What is the copy-on-write principle?
Copy-on-write (COW) is a technique used to optimize the performance of computer systems by avoiding the need to copy data unnecessarily.
